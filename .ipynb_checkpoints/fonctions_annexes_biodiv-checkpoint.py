# fonctions_annexes_biodiv.py
import pandas as pd
import math
import numpy as np
import geopandas as gpd
import re
from IPython.display import display, HTML
import matplotlib.pyplot as plt


def round_to_sig(num, sig=3, direction='nearest'):
    if num is None:
        raise ValueError("La valeur Ã  arrondir ne doit pas Ãªtre None.")
    if num == 0:
        return 0
    # DÃ©terminer l'ordre de grandeur du nombre
    order_of_magnitude = math.floor(math.log10(abs(num)))
    # Calculer le facteur de multiplication
    factor = 10**(sig - order_of_magnitude - 1)
    if direction == 'nearest':
        return round(num * factor) / factor
    elif direction == 'up':
        return math.ceil(num * factor) / factor
    elif direction == 'down':
        return math.floor(num * factor) / factor
    else:
        raise ValueError("Direction must be 'nearest', 'up', or 'down'")

def generer_dictionnaire_taxonomie(df,cle_ID='cdRef'):
    # DÃ©finir les colonnes attendues
    colonnes_attendues = ['speciesKey','cdRef','cdNom','taxonID','taxonKey',
                          'species','vernacularName_fr','vernacularName_en','genus','family','order','class','phylum','kingdom', 
                          'nomScientifique','nomVernaculaire','genre', 'famille', 'ordre', 'classe', 'regne',
                      'taxonRank','especeProtegee','statutBiogeoEspeceTaxref', 'habitatEspeceTaxref','occurrenceID']
    
    # VÃ©rifier quelles colonnes sont prÃ©sentes dans le DataFrame
    colonnes_presentes = [col for col in colonnes_attendues if col in df.columns]
    
    df_filtered=df[colonnes_presentes]

    #Trier le DataFrame par le nombre de valeurs non nulles dans chaque ligne, en ordre dÃ©croissant
    df_sorted = df_filtered.loc[df_filtered.notnull().sum(axis=1).sort_values(ascending=False).index]
    
    # Supprimer les doublons en fonction de 'cle_ID'
    dico_taxo = df_sorted.drop_duplicates(subset=[cle_ID])
    
    # SÃ©lectionner uniquement les colonnes prÃ©sentes
    dico_taxo = dico_taxo[colonnes_presentes]

    return dico_taxo

def afficher_dataframe(df,liste_colonnes,col_sort=None):
    # Boucle sur les colonnes de la liste
    colonnes_obs = [col for col in df.columns if 'nombreObs' in col.lower()]
    for col in colonnes_obs:
        if col in df.columns:
            if np.issubdtype(df[col].dtype, np.integer):  # VÃ©rifie si la colonne est dÃ©jÃ  en entier
                continue  # Si c'est dÃ©jÃ  un entier, on passe
            else:
                # Sinon, arrondit Ã  3 chiffres significatifs
                df[col] = df[col].apply(lambda x: round(x, 1) if pd.notnull(x) else x)

    df=df[liste_colonnes]
    df= df.loc[:, ~df.columns.duplicated()]
    if col_sort is not None:
        df=df.sort_values([col_sort], ascending=[False])
    df =df.reset_index(drop=True)
    #display(HTML(df.to_html(escape=False)))
    return df

def completer_df(df_local,df_global,cle_geo='codeMaille10Km',cle_ID='cdRef'):
    # Ã‰tape 1: RÃ©cupÃ©rer les valeurs uniques de codeMaille10Km et nomScientifique
    unique_codeMaille = df_local[cle_geo].unique()
    unique_nomScientifique = df_global[cle_ID].unique()
    
    # Ã‰tape 2: CrÃ©er toutes les combinaisons possibles
    combinations = pd.MultiIndex.from_product([unique_codeMaille, unique_nomScientifique], names=[cle_geo, cle_ID]).to_frame(index=False)

    liste_nombres=[col for col in df_local.columns if 'nombreObs' in col]
    
    df_local_reduit=df_local[[cle_geo,cle_ID]+liste_nombres]
    
    # Ã‰tape 3: Fusionner avec le DataFrame original pour identifier les lignes manquantes
    df_local_complet = combinations.merge(df_local_reduit, on=[cle_geo, cle_ID], how='left')

    df_local_complet=df_local_complet.fillna(0)
    
    # Ã‰tape 4: Remplir les valeurs manquantes dans les colonnes normalisÃ©es
    df_dico=generer_dictionnaire_taxonomie(df_global,cle_ID=cle_ID)
    df_local_complet=pd.merge(df_local_complet,df_dico,on=cle_ID)
    
    return df_local_complet

def lister_mailles_dans_site(df_geo,parc_gpd,nom_parc,taux_min=0.5,cle_geo='codeMaille10Km',cle_nom_site='NOM_SITE',methode='exact'):
    # Assurons-nous que les deux GeoDataFrames sont dans le mÃªme systÃ¨me de coordonnÃ©es
    df_geo = df_geo.to_crs(parc_gpd.crs)
    if methode == 'contains':
        parc_gpd_filt=parc_gpd[parc_gpd[cle_nom_site].str.contains(nom_parc,case=False)]
    elif methode == 'exact':
        parc_gpd_filt=parc_gpd[parc_gpd[cle_nom_site]==nom_parc]
    else: 
        print("La mÃ©thode n'est pas valide, methode= 'contains' ou 'exact'")
        parc_gpd_filt=parc_gpd[parc_gpd[cle_nom_site]==nom_parc]
    
    # Calculer l'union de toutes les gÃ©omÃ©tries de PNR_gpd avec union_all() au lieu de unary_union
    pnr_union = parc_gpd_filt.geometry.union_all()
    joined = gpd.sjoin(df_geo, parc_gpd, how="inner", predicate="intersects")
    # Calculer l'intersection entre chaque gÃ©omÃ©trie de carte_maille et PNR_gpd
    joined["intersection"] = joined.apply(lambda row: row["geometry"].intersection(pnr_union), axis=1)
    
    # Calculer la surface des gÃ©omÃ©tries et de leur intersection
    joined["area_original"] = joined["geometry"].area
    joined["area_intersection"] = joined["intersection"].area
    
    # Filtrer pour garder les gÃ©omÃ©tries dont l'intersection couvre au moins 50% de leur surface
    filtered = joined[joined["area_intersection"] >= taux_min* joined["area_original"]]
    
    # Supprimer les colonnes temporaires si elles ne sont pas nÃ©cessaires
    filtered = filtered.drop(columns=["intersection", "area_original", "area_intersection", "index_right"])
    liste_mailles=filtered[cle_geo].reset_index(drop=True)
    return liste_mailles

def ajouter_nom_site_df(df_inpn,df_geo,parc_gpd,taux_min=0.5,cle_geo='codeMaille10Km',cle_nom_site='NOM_SITE',display=True,methode='all'):
    liste_noms=parc_gpd[cle_nom_site].str.replace(r"\s*\[aire d'adhÃ©sion\]", "", regex=True, flags=re.IGNORECASE).drop_duplicates().reset_index(drop=True)
    for nom_site in liste_noms:
        liste_mailles=lister_mailles_dans_site(df_geo,parc_gpd,nom_site,taux_min,cle_geo,cle_nom_site,methode)
        if display is True:
            print(f"{len(liste_mailles)} mailles ont au moins {round(taux_min*100)}% de leur surface comprise dans le PN {nom_site}")
        df_inpn.loc[df_inpn[cle_geo].isin(liste_mailles),cle_nom_site]=nom_site
    return df_inpn


def filtrer_grille(grid, lat_min, lat_max, lon_min, lon_max):
    # Exclure les cellules hors des bornes donnÃ©es
    grid = grid[(
        (grid.geometry.centroid.y >= lat_min) &
        (grid.geometry.centroid.y <= lat_max) &
        (grid.geometry.centroid.x >= lon_min) &
        (grid.geometry.centroid.x <= lon_max)
    )]
    return grid

def afficher_carte_monde(world_terrestre,ecart=15):
    # CrÃ©er la figure et l'axe
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # Tracer les donnÃ©es gÃ©ographiques
    world_terrestre.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7)
    
    # Ajouter des mÃ©ridiens et des parallÃ¨les Ã  intervalles rÃ©guliers
    # DÃ©finir les intervalles
    meridians = np.arange(-180, 181, ecart)  # Tous les 30 degrÃ©s
    parallels = np.arange(-90, 91, ecart)   # Tous les 30 degrÃ©s
    
    # Tracer les mÃ©ridiens
    for meridian in meridians:
        ax.plot([meridian, meridian], [-90, 90], color='gray', linestyle='--', linewidth=0.5)
    
    # Tracer les parallÃ¨les
    for parallel in parallels:
        ax.plot([-180, 180], [parallel, parallel], color='gray', linestyle='--', linewidth=0.5)
    
    # Ajouter des Ã©tiquettes pour les mÃ©ridiens et les parallÃ¨les
    for meridian in meridians:
        ax.text(meridian, -95, f"{meridian}Â°", color='black', ha='center', fontsize=8)
    for parallel in parallels:
        ax.text(-185, parallel, f"{parallel}Â°", color='black', va='center', fontsize=8)
    
    # Ajouter un titre
    ax.set_title('Carte du monde avec mÃ©ridiens et parallÃ¨les', fontsize=14)
    
    # Ajuster les limites
    ax.set_xlim(-180, 180)
    ax.set_ylim(-90, 90)
    
    # Afficher la carte
    plt.show()

def filtrer_geo(df_biodiv, carte_maille, cle_geo,
                           lon_min=-11, lon_max=25, lat_min=32, lat_max=55):
    """
    Filtre et agrÃ¨ge les donnÃ©es de biodiversitÃ© en fonction des limites gÃ©ographiques et des mailles valides.

    ParamÃ¨tres :
    ------------
    - df_biodiv : DataFrame contenant les observations de biodiversitÃ©
    - carte_maille : DataFrame contenant les mailles gÃ©ographiques
    - dico_taxo : DataFrame contenant les informations taxonomiques
    - cle_geo : str, nom de la colonne contenant l'identifiant des mailles
    - cle_ID : str, nom de la colonne contenant l'identifiant des espÃ¨ces
    - filtrage_grille : bool, True pour appliquer un filtre gÃ©ographique sur la grille
    - lon_min, lon_max, lat_min, lat_max : float, limites gÃ©ographiques du filtrage

    Retourne :
    ----------
    - df_biodiv_periode : DataFrame filtrÃ© et agrÃ©gÃ© par pÃ©riode
    - df_biodiv_sansperiode : DataFrame filtrÃ© et agrÃ©gÃ© sans pÃ©riode
    """
    
    # VÃ©rifier si le GeoDataFrame a un CRS projetÃ©, sinon le reprojeter
    if carte_maille.crs is None or carte_maille.crs.is_geographic:
        print("ðŸ”„ Reprojection des donnÃ©es en EPSG:3857 pour un bon filtrage")
        carte_maille = carte_maille.to_crs(epsg=3857)

    # Calcul des centroides aprÃ¨s reprojection
    carte_maille["centroid"] = carte_maille.geometry.centroid
    carte_maille_filt = carte_maille[
        (carte_maille["centroid"].y >= lat_min) & (carte_maille["centroid"].y <= lat_max) &
        (carte_maille["centroid"].x >= lon_min) & (carte_maille["centroid"].x <= lon_max)
    ]
               
    print("Filtrage gÃ©ographique activÃ©")
    carte_maille_filt = filtrer_grille(carte_maille, lat_min, lat_max, lon_min, lon_max)
    df_biodiv = df_biodiv[df_biodiv[cle_geo].isin(carte_maille_filt[cle_geo])]

    return df_biodiv


def filtrer_categorie(df, filtre, filtres):
    """
    Applique un filtre spÃ©cifique sur un DataFrame et retourne un DataFrame filtrÃ©.

    :param df: DataFrame sur lequel appliquer le filtre.
    :param filtre: Nom du filtre Ã  appliquer (doit Ãªtre une clÃ© du dictionnaire `filtres`).
    :param filtres: Dictionnaire des filtres (modifiable si besoin).
    :return: DataFrame filtrÃ©.
    """
    # VÃ©rifier si le filtre demandÃ© existe
    if filtre not in filtres:
        raise ValueError(f"Filtre '{filtre}' non reconnu. Filtres disponibles : {list(filtres.keys())}")

    # Construire les conditions de filtrage
    conditions = filtres[filtre]
    filtres_list = [(df[col].isin(valeurs)) for col, valeurs in conditions.items()]

    # Appliquer le filtre (garde les lignes qui correspondent Ã  AU MOINS une condition)
    df_filt = df[pd.concat(filtres_list, axis=1).any(axis=1)].copy()

    return df_filt


