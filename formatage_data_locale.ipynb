{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab2d9fc-467a-4e9f-a460-b698c3501615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import CRS\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "import importlib\n",
    "import fonctions_annexes_biodiv\n",
    "importlib.reload(fonctions_annexes_biodiv)\n",
    "from fonctions_annexes_biodiv import generer_dictionnaire_taxonomie\n",
    "\n",
    "%matplotlib qt\n",
    "path = 'C:/Users/anormand/Documents/Projet Python/Biodiv/Data'  # chemin vers le fichier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3786d35-69d5-450d-aaab-4239250c3dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrees_per_km(latitude):\n",
    "    \"\"\"\n",
    "    Calculate the degree equivalent of 1 km for both latitude and longitude\n",
    "    at a specific latitude.\n",
    "\n",
    "    :param latitude: Latitude in degrees\n",
    "    :return: Tuple (lat_deg_per_km, lon_deg_per_km)\n",
    "    \"\"\"\n",
    "    # 1 degree of latitude is ~111.32 km everywhere\n",
    "    lat_deg_per_km = 1 / 111.32\n",
    "\n",
    "    # 1 degree of longitude varies with latitude\n",
    "    lon_deg_per_km = 1 / 111.32 / math.cos(math.radians(latitude))\n",
    "\n",
    "    return lat_deg_per_km, lon_deg_per_km\n",
    "\n",
    "def create_country_grid_WGS84(gdf, country_code,col_code=\"color_code\", grid_size_km=10,midpoint_lat=None,display=False):\n",
    "    \"\"\"\n",
    "    Generates a grid within the specified country's boundaries with cell names based on \n",
    "    coordinates and grid size using WGS 84 reference system (EPSG:4326).\n",
    "    \n",
    "    Parameters:\n",
    "    - gdf: GeoDataFrame containing global boundaries with a column for the country's unique code (e.g., \"color_code\").\n",
    "    - country_name: Name of the country for which to generate the grid.\n",
    "    - grid_size_km: Size of the grid cells in kilometers (default is 10 km x 10 km).\n",
    "    \n",
    "    Returns:\n",
    "    - grid: GeoDataFrame with grid cells and a 'name' column for each cell's unique identifier.\n",
    "    \"\"\"\n",
    "    # Convert grid size from kilometers to degrees (approximation for WGS 84)\n",
    "    # 1 degree of latitude ≈ 111 km, but longitude degrees vary by latitude\n",
    "    # Filter to get the specified country\n",
    "    country = gdf[gdf[col_code].isin(country_code)]\n",
    "\n",
    "\n",
    "    if country.empty:\n",
    "        raise ValueError(f\"Country '{country_code}' not found in the GeoDataFrame.\")\n",
    "\n",
    "    # Define a function to create a grid of specified resolution (in degrees) with alignment to a reference point\n",
    "    def create_grid(country, grid_size=10, reference_point=(0, 0),midpoint_lat=None):\n",
    "        # Unpack reference point\n",
    "        ref_x, ref_y = reference_point\n",
    "        \n",
    "        country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
    "    \n",
    "        # Get the bounds of the input GeoDataFrame\n",
    "        minx, miny, maxx, maxy = country_geometry.bounds\n",
    "\n",
    "\n",
    "            # Step 3: Adjust bounding box to align with (0, 0)\n",
    "        # Use approximate degrees per km for the middle of the country\n",
    "        if midpoint_lat is None:\n",
    "            midpoint_lat = (miny + maxy) / 2\n",
    "        lat_deg_per_km, lon_deg_per_km = degrees_per_km(midpoint_lat)\n",
    "        dy = grid_size * lat_deg_per_km\n",
    "        dx = grid_size * lon_deg_per_km\n",
    "    \n",
    "        # Align the starting point to the reference point\n",
    "        start_x = ref_x + ((minx - ref_x) // dx) * dx\n",
    "        start_y = ref_y + ((miny - ref_y) // dy) * dy\n",
    "    \n",
    "        grid_cells = []\n",
    "        x = start_x\n",
    "        while x < maxx:\n",
    "            y = start_y\n",
    "            while y < maxy:\n",
    "                cell = box(x, y, x + dx, y + dy)\n",
    "                min_lon, min_lat, max_lon, max_lat = cell.bounds\n",
    "    \n",
    "                # Append the grid cell along with its bounds\n",
    "                grid_cells.append({\n",
    "                    \"geometry\": cell,\n",
    "                    \"min_lon\": min_lon,\n",
    "                    \"min_lat\": min_lat,\n",
    "                    \"max_lon\": max_lon,\n",
    "                    \"max_lat\": max_lat\n",
    "                })\n",
    "                y += dy\n",
    "            x += dx\n",
    "    \n",
    "        # Create a GeoDataFrame from the grid cells with the additional columns\n",
    "        grid_gdf = gpd.GeoDataFrame(\n",
    "            grid_cells, \n",
    "            columns=[\"geometry\", \"min_lon\", \"min_lat\", \"max_lon\", \"max_lat\"], \n",
    "            crs=country.crs\n",
    "        )\n",
    "        \n",
    "        return grid_gdf\n",
    "\n",
    "    \n",
    "    # Create the grid and clip it to the country's boundary\n",
    "\n",
    "    grid = create_grid(country, grid_size=grid_size_km,midpoint_lat=midpoint_lat)\n",
    "    grid = grid[grid.intersects(country.unary_union)]\n",
    "    \n",
    "    # Generate names based on cell centroid latitude and longitude\n",
    "    def generate_grid_name(cell, grid_size_km):\n",
    "        centroid = cell.geometry.centroid\n",
    "        lon, lat = centroid.x, centroid.y\n",
    "        lon_label = f\"E{int(abs(lon) * 10000):05d}\" if lon >= 0 else f\"W{int(abs(lon) * 10000):05d}\"\n",
    "        lat_label = f\"N{int(abs(lat) * 10000):05d}\" if lat >= 0 else f\"S{int(abs(lat) * 10000):05d}\"\n",
    "        return f\"{grid_size_km}km{lon_label}{lat_label}\"\n",
    "\n",
    "    # Apply naming to each grid cell\n",
    "    grid[\"cell_name\"] = grid.apply(lambda cell: generate_grid_name(cell, grid_size_km), axis=1)\n",
    "    #grid[\"country_code\"] = country_code\n",
    "\n",
    "    if display is True:\n",
    "        # Plot the grid and the country boundary for reference\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        gdf.plot(ax=ax, edgecolor=\"black\", linewidth=0.5)\n",
    "        country.plot(ax=ax, edgecolor=\"red\", linewidth=2, facecolor=\"none\")\n",
    "        grid.plot(ax=ax, color=\"lightblue\", edgecolor=\"grey\", alpha=0.6)\n",
    "    \n",
    "        plt.show()\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def add_grid_to_country(df_country, grid,cle_geo):\n",
    "    \"\"\"\n",
    "    Optimized version of adding the corresponding grid cell to each row in df_country based on latitude and longitude.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_country: DataFrame containing the columns 'decimalLatitude' and 'decimalLongitude'.\n",
    "    - grid: DataFrame containing the grid cells with 'name', 'min_lon', 'min_lat', 'max_lon', and 'max_lat' columns.\n",
    "    \n",
    "    Returns:\n",
    "    - df_country: Updated DataFrame with an additional 'grid_name' column indicating the grid cell for each point.\n",
    "    \"\"\"\n",
    "    # Convert grid bounds to NumPy arrays for efficient vectorized comparison\n",
    "    min_lons = grid['min_lon'].values\n",
    "    max_lons = grid['max_lon'].values\n",
    "    min_lats = grid['min_lat'].values\n",
    "    max_lats = grid['max_lat'].values\n",
    "    grid_names = grid[cle_geo].values\n",
    "    \n",
    "    # Initialize an array to store the grid names\n",
    "    grid_names_for_points = []\n",
    "    \n",
    "    # Iterate over each point in df_country and apply vectorized comparison\n",
    "    for lon, lat in zip(df_country['decimalLongitude'], df_country['decimalLatitude']):\n",
    "        # Find the grid cell by comparing the point coordinates with grid bounds\n",
    "        matching_grid = np.where((min_lons <= lon) & (lon <= max_lons) & (min_lats <= lat) & (lat <= max_lats))[0]\n",
    "        \n",
    "        if matching_grid.size > 0:\n",
    "            grid_names_for_points.append(grid_names[matching_grid[0]])  # Take the first matching grid cell\n",
    "        else:\n",
    "            grid_names_for_points.append(None)  # No matching grid\n",
    "    \n",
    "    # Add the grid names to the DataFrame\n",
    "    df_country['grid_name'] = grid_names_for_points\n",
    "    \n",
    "    return df_country\n",
    "\n",
    "def formater_maille_espece_GBIF(df,cle_geo='codeMaille10Km',cle_ID='cdRef',annee_min=None,bornes_temporelles=None):\n",
    "    df_dico=generer_dictionnaire_taxonomie(df,cle_ID)\n",
    "    # Convertir la colonne 'year' en int\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Convertir la colonne 'cdNom' en int\n",
    "    df[cle_ID] = df[cle_ID].astype(int)\n",
    "\n",
    "    if annee_min is not None:\n",
    "        df=df[df['year']>=annee_min]\n",
    "    \n",
    "    # Choisir des bornes temporelles et assigner une période aux données\n",
    "    if bornes_temporelles is not None:\n",
    "        df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles, \n",
    "                       labels=[f'Période {i+1}: {bornes_temporelles[i]+1} à {bornes_temporelles[i+1]}' for i in range(len(bornes_temporelles) - 1)],\n",
    "                       include_lowest=False)  # include_lowest=True inclut la borne inférieureure\n",
    "        # Compter le nombre de données dans chaque intervalle\n",
    "        compte_par_periode = df['periode'].value_counts()\n",
    "        print(compte_par_periode)\n",
    "         # Compter les occurrences d'observation de chaque taxon pour chaque code et période\n",
    "        df_maille_espece = df.groupby([cle_geo, cle_ID,'periode'], observed=True).size().reset_index(name='nombreObs')\n",
    "        #df_maille_espece = df.groupby([cle_geo, cle_ID,'periode'], observed=True)['individualCount'].sum().reset_index(name='nombreObs')\n",
    "        #eventuellement remplacer ['individualCount'].sum() par .size() \n",
    "       \n",
    "    else:\n",
    "        # Compter les occurrences d'observation de chaque taxon pour chaque code\n",
    "        df_maille_espece = df.groupby([cle_geo, cle_ID], observed=True).size().reset_index(name='nombreObs')\n",
    "        #eventuellement remplacer ['individualCount'].sum() par .size() \n",
    "        \n",
    "    df_maille_espece=pd.merge(df_maille_espece,df_dico,on=cle_ID)\n",
    "    \n",
    "    return df_maille_espece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16fe4b3-ddcc-4d31-b946-6a4e7f821922",
   "metadata": {},
   "outputs": [],
   "source": [
    "departement_fichier = r'C:\\Users\\anormand\\Documents\\Projet Python\\Biodiv\\Data\\GBIF_France\\SIG\\carte_departements.geojson'  # Remplace par le chemin vers ton fichier\n",
    "departement_gpd = gpd.read_file(departement_fichier)\n",
    "\n",
    "PNR_fichier = r'C:\\Users\\anormand\\Documents\\Projet Python\\Biodiv\\Data\\GBIF_France\\SIG\\N_ENP_PNR_S_000.shx'  # Remplace par le chemin vers ton fichier\n",
    "PNR_gpd = gpd.read_file(PNR_fichier)\n",
    "PNR_gpd=PNR_gpd[['NOM_SITE','geometry']]\n",
    "\n",
    "PN_fichier = r'C:\\Users\\anormand\\Documents\\Projet Python\\Biodiv\\Data\\GBIF_France\\SIG\\N_ENP_PN_S_000.shx'  # Remplace par le chemin vers ton fichier\n",
    "PN_gpd = gpd.read_file(PN_fichier)\n",
    "PN_gpd=PN_gpd[['NOM_SITE','geometry']]\n",
    "\n",
    "# Reprojeter en WGS84 (EPSG:4326)\n",
    "PNR_gpd = PNR_gpd.to_crs(epsg=4326)\n",
    "PN_gpd = PN_gpd.to_crs(epsg=4326)\n",
    "departement_gpd = departement_gpd.to_crs(epsg=4326)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cf3e29-6559-472b-999c-d31bac80179c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>nom</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Ain</td>\n",
       "      <td>POLYGON ((4.78021 46.17668, 4.78024 46.18905, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>Aisne</td>\n",
       "      <td>POLYGON ((3.17296 50.01131, 3.17382 50.01186, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>Allier</td>\n",
       "      <td>POLYGON ((3.03207 46.79491, 3.03424 46.7908, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>POLYGON ((5.67604 44.19143, 5.67817 44.19051, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05</td>\n",
       "      <td>Hautes-Alpes</td>\n",
       "      <td>POLYGON ((6.26057 45.12685, 6.26417 45.12641, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>Essonne</td>\n",
       "      <td>POLYGON ((2.22656 48.7761, 2.22866 48.77451, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>Hauts-de-Seine</td>\n",
       "      <td>POLYGON ((2.29097 48.95097, 2.29162 48.95077, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>Seine-Saint-Denis</td>\n",
       "      <td>POLYGON ((2.55306 49.00982, 2.55814 49.01201, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>Val-de-Marne</td>\n",
       "      <td>POLYGON ((2.3319 48.81701, 2.33371 48.81677, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>Val-d'Oise</td>\n",
       "      <td>POLYGON ((2.59052 49.07965, 2.59013 49.07786, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                      nom  \\\n",
       "0    01                      Ain   \n",
       "1    02                    Aisne   \n",
       "2    03                   Allier   \n",
       "3    04  Alpes-de-Haute-Provence   \n",
       "4    05             Hautes-Alpes   \n",
       "..  ...                      ...   \n",
       "91   91                  Essonne   \n",
       "92   92           Hauts-de-Seine   \n",
       "93   93        Seine-Saint-Denis   \n",
       "94   94             Val-de-Marne   \n",
       "95   95               Val-d'Oise   \n",
       "\n",
       "                                             geometry  \n",
       "0   POLYGON ((4.78021 46.17668, 4.78024 46.18905, ...  \n",
       "1   POLYGON ((3.17296 50.01131, 3.17382 50.01186, ...  \n",
       "2   POLYGON ((3.03207 46.79491, 3.03424 46.7908, 3...  \n",
       "3   POLYGON ((5.67604 44.19143, 5.67817 44.19051, ...  \n",
       "4   POLYGON ((6.26057 45.12685, 6.26417 45.12641, ...  \n",
       "..                                                ...  \n",
       "91  POLYGON ((2.22656 48.7761, 2.22866 48.77451, 2...  \n",
       "92  POLYGON ((2.29097 48.95097, 2.29162 48.95077, ...  \n",
       "93  POLYGON ((2.55306 49.00982, 2.55814 49.01201, ...  \n",
       "94  POLYGON ((2.3319 48.81701, 2.33371 48.81677, 2...  \n",
       "95  POLYGON ((2.59052 49.07965, 2.59013 49.07786, ...  \n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departement_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee03cf7-bdca-434a-9325-808c64f9ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données (si ce n'est pas encore un GeoDataFrame)\n",
    " # Remplace par ton fichier si besoin\n",
    "\n",
    "# Nettoyer les noms des sites\n",
    "PN_gpd[\"NOM_SITE\"] = PN_gpd[\"NOM_SITE\"].str.replace(r\"\\s*\\[aire d'adhésion\\]\\s*\", \"\", regex=True)\n",
    "PN_gpd[\"NOM_SITE\"] = PN_gpd[\"NOM_SITE\"].str.replace(r\"\\s*\\[Aire d'adhésion\\]\\s*\", \"\", regex=True)\n",
    "\n",
    "\n",
    "# Fusionner les géométries par site\n",
    "PN_gpd_fusionne = PN_gpd.dissolve(by=\"NOM_SITE\")\n",
    "\n",
    "# Sauvegarde si besoin\n",
    "#gdf_fusionne.to_file(\"output.geojson\", driver=\"GeoJSON\")\n",
    "PN_gpd_fusionne.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3d140b-7fa0-42f1-a5df-bf74cd1aed2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOM_SITE</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calanques</td>\n",
       "      <td>POLYGON ((5.34577 43.28208, 5.34579 43.28206, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cévennes</td>\n",
       "      <td>POLYGON ((3.44487 44.02465, 3.44482 44.02463, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ecrins</td>\n",
       "      <td>POLYGON ((6.01676 44.9867, 6.01599 44.98834, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Forêts</td>\n",
       "      <td>MULTIPOLYGON (((4.67735 47.73921, 4.67768 47.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mercantour</td>\n",
       "      <td>POLYGON ((7.58032 44.02968, 7.57988 44.02961, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Port-Cros</td>\n",
       "      <td>MULTIPOLYGON (((6.20402 43.14906, 6.20408 43.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pyrénées</td>\n",
       "      <td>POLYGON ((0.11582 42.83451, 0.11638 42.83422, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vanoise</td>\n",
       "      <td>POLYGON ((6.5105 45.44497, 6.51057 45.44497, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NOM_SITE                                           geometry\n",
       "0   Calanques  POLYGON ((5.34577 43.28208, 5.34579 43.28206, ...\n",
       "1    Cévennes  POLYGON ((3.44487 44.02465, 3.44482 44.02463, ...\n",
       "2      Ecrins  POLYGON ((6.01676 44.9867, 6.01599 44.98834, 6...\n",
       "3      Forêts  MULTIPOLYGON (((4.67735 47.73921, 4.67768 47.7...\n",
       "4  Mercantour  POLYGON ((7.58032 44.02968, 7.57988 44.02961, ...\n",
       "5   Port-Cros  MULTIPOLYGON (((6.20402 43.14906, 6.20408 43.1...\n",
       "6    Pyrénées  POLYGON ((0.11582 42.83451, 0.11638 42.83422, ...\n",
       "7     Vanoise  POLYGON ((6.5105 45.44497, 6.51057 45.44497, 6..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PN_gpd_fusionne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf5138c-d811-4855-91d6-f262c347f666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_cleaned.to_csv(\"C:/Users/anormand/Documents/Projet Python/Biodiv/Data/GBIF_\"+\\n                  country_name.replace(\\' \\', \\'_\\')+\\n                  \"/Filtered\"+\\n                  \"/data_GBIF_\"+country_name.replace(\\' \\', \\'_\\')+\"_\"+str(grid_size_km)+\"Km_filtered.csv\",\\n                  index=False)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sauvegarde du fichier pré-traité sous le format 1 ligne = 1 observation\n",
    "\"\"\"\n",
    "df_cleaned.to_csv(\"C:/Users/anormand/Documents/Projet Python/Biodiv/Data/GBIF_\"+\n",
    "                  country_name.replace(' ', '_')+\n",
    "                  \"/Filtered\"+\n",
    "                  \"/data_GBIF_\"+country_name.replace(' ', '_')+\"_\"+str(grid_size_km)+\"Km_filtered.csv\",\n",
    "                  index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d972664-cf20-4dc9-9cc2-4ac20c679e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:23: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:79: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:79: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:23: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  local_grid.to_file(r\"C:\\Users\\anormand\\Documents\\Projet Python\\Biodiv\\Data\\GBIF_\"+country_name.replace(' ', '_')+\"\\SIG\"+r\"/\"+zone_name_str+\"_grid_\"+str(grid_size_km)+\"km.geojson\",\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:79: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  local_grid.to_file(r\"C:\\Users\\anormand\\Documents\\Projet Python\\Biodiv\\Data\\GBIF_\"+country_name.replace(' ', '_')+\"\\SIG\"+r\"/\"+zone_name_str+\"_grid_\"+str(grid_size_km)+\"km.geojson\",\n"
     ]
    }
   ],
   "source": [
    "def importer_data_zone(zone_name,var_name,zone_gpd,country_name,grid_size_km):\n",
    "\n",
    "    # Génération de la grille pour le pays choisi\n",
    "    cle_geo=\"codeMaille\"+str(grid_size_km)+'Km'\n",
    "    zone = zone_gpd[zone_gpd[var_name].isin(zone_name)]\n",
    "    zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
    "\n",
    "    # Génération de la grille pour le pays choisi\n",
    "    # Get the bounds of the input GeoDataFrame\n",
    "    minx, miny, maxx, maxy = zone_geometry.bounds\n",
    "    \n",
    "    # Step 3: Adjust bounding box to align with (0, 0)\n",
    "    # Use approximate degrees per km for the middle of the country\n",
    "    midpoint_lat = (miny + maxy) / 2\n",
    "    \n",
    "    local_grid = create_country_grid_WGS84(zone_gpd, zone_name,var_name,grid_size_km=grid_size_km,midpoint_lat=midpoint_lat,display=True)\n",
    "    nouveaux_noms_columns = {'cell_name': cle_geo}\n",
    "    local_grid = local_grid.rename(columns=nouveaux_noms_columns)\n",
    "    nouveaux_noms_columns = {'country_code': 'zone_name'}\n",
    "    local_grid = local_grid.rename(columns=nouveaux_noms_columns)\n",
    "    zone_name_str = \"_\".join(zonename.replace(\" \", \"_\") for zonename in zone_name)\n",
    "    # Sauvegarder le fichier grille\n",
    "    local_grid.to_file(r\"C:\\Users\\anormand\\Documents\\Projet Python\\Biodiv\\Data\\GBIF_\"+country_name.replace(' ', '_')+\"\\SIG\"+r\"/\"+zone_name_str+\"_grid_\"+str(grid_size_km)+\"km.geojson\", \n",
    "                                 driver=\"GeoJSON\")\n",
    "    ### Importer les données de biodiversité du pays ###\n",
    "\n",
    "    colonnes_a_importer=['kingdom','phylum','class','order','family','genus','species','verbatimScientificName',\n",
    "                             'taxonRank','countryCode','occurrenceStatus', 'individualCount', \n",
    "                         'decimalLongitude','decimalLatitude','eventDate','taxonKey','speciesKey','occurrenceID', 'year']\n",
    "    fichier = \"C:/Users/anormand/Documents/Projet Python/Biodiv/Data/GBIF_\"+country_name.replace(' ', '_')+\"/Raw/extractGBIF_\"+country_name.replace(' ', '_')+\"_12112024.csv\"  # Remplace par le chemin vers ton fichier\n",
    "\n",
    "    \n",
    "    # Lire le fichier en filtrant directement\n",
    "    chunksize = 10000000  # Lecture par morceaux pour gros fichiers\n",
    "    filtered_data = []\n",
    "    \n",
    "    # Lire en chunks (utile pour les fichiers volumineux)\n",
    "    for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
    "        # Convertir en float en gérant les erreurs\n",
    "        chunk[\"decimalLatitude\"] = pd.to_numeric(chunk[\"decimalLatitude\"], errors='coerce')\n",
    "        chunk[\"decimalLongitude\"] = pd.to_numeric(chunk[\"decimalLongitude\"], errors='coerce')\n",
    "    \n",
    "        # Filtrer les valeurs valides\n",
    "        chunk_filtered = chunk.dropna(subset=[\"decimalLatitude\", \"decimalLongitude\"])\n",
    "        chunk_filtered = chunk_filtered[\n",
    "            (chunk_filtered[\"decimalLongitude\"] >= minx) & (chunk_filtered[\"decimalLongitude\"] <= maxx) &\n",
    "            (chunk_filtered[\"decimalLatitude\"] >= miny) & (chunk_filtered[\"decimalLatitude\"] <= maxy)\n",
    "        ]\n",
    "        filtered_data.append(chunk_filtered)\n",
    "    \n",
    "    # Concaténer les morceaux filtrés\n",
    "    df_biodiv = pd.concat(filtered_data, ignore_index=True)\n",
    "\n",
    "    return df_biodiv\n",
    "\n",
    "def formater_data_PN_all_in_one(df_biodiv,zone_name,var_name,zone_gpd,country_name,grid_size_km,\n",
    "                                cle_ID='speciesKey',cle_date='year',\n",
    "                                annee_mini=0,bornes_temporelles=[1800, 1990,2010, 2024]):\n",
    "    # Génération de la grille pour le pays choisi\n",
    "    cle_geo=\"codeMaille\"+str(grid_size_km)+'Km'\n",
    "    zone = zone_gpd[zone_gpd[var_name].isin(zone_name)]\n",
    "    zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
    "\n",
    "    # Génération de la grille pour le pays choisi\n",
    "    # Get the bounds of the input GeoDataFrame\n",
    "    minx, miny, maxx, maxy = zone_geometry.bounds\n",
    "    \n",
    "    # Step 3: Adjust bounding box to align with (0, 0)\n",
    "    # Use approximate degrees per km for the middle of the country\n",
    "    midpoint_lat = (miny + maxy) / 2\n",
    "    \n",
    "    local_grid = create_country_grid_WGS84(zone_gpd, zone_name,var_name,grid_size_km=grid_size_km,midpoint_lat=midpoint_lat,display=True)\n",
    "    nouveaux_noms_columns = {'cell_name': cle_geo}\n",
    "    local_grid = local_grid.rename(columns=nouveaux_noms_columns)\n",
    "    nouveaux_noms_columns = {'country_code': 'zone_name'}\n",
    "    local_grid = local_grid.rename(columns=nouveaux_noms_columns)\n",
    "    zone_name_str = \"_\".join(zonename.replace(\" \", \"_\") for zonename in zone_name)\n",
    "    # Sauvegarder le fichier grille\n",
    "    local_grid.to_file(r\"C:\\Users\\anormand\\Documents\\Projet Python\\Biodiv\\Data\\GBIF_\"+country_name.replace(' ', '_')+\"\\SIG\"+r\"/\"+zone_name_str+\"_grid_\"+str(grid_size_km)+\"km.geojson\", \n",
    "                                 driver=\"GeoJSON\")\n",
    "                       \n",
    "    # Compter le nombre de NaN par colonne\n",
    "    df_biodiv['eventDate'] = pd.to_datetime(df_biodiv['eventDate'], errors='coerce', utc=True)\n",
    "    \n",
    "    df_biodiv['year'] = df_biodiv['year'].fillna(df_biodiv['eventDate'].dt.year)\n",
    "\n",
    "    # Associer chaque observation à une maille de la grille\n",
    "    \n",
    "    # Assurez-vous que 'decimalLongitude' et 'decimalLatitude' sont des colonnes numériques\n",
    "    df_biodiv['decimalLongitude'] = pd.to_numeric(df_biodiv['decimalLongitude'], errors='coerce')\n",
    "    df_biodiv['decimalLatitude'] = pd.to_numeric(df_biodiv['decimalLatitude'], errors='coerce')\n",
    "    \n",
    "    # Filtrer les lignes où les coordonnées sont NaN\n",
    "    df_biodiv = df_biodiv.dropna(subset=['decimalLongitude', 'decimalLatitude',cle_ID]).reset_index(drop=True)\n",
    "    \n",
    "    # Ajouter le grid aux points\n",
    "    df_biodiv_with_grid = add_grid_to_country(df_biodiv, local_grid,cle_geo)\n",
    "    \n",
    "\n",
    "    # Pré-traitement des données\n",
    "    \n",
    "    # Lire uniquement les colonnes spécifiées du fichier dans un DataFrame\n",
    "    df=df_biodiv_with_grid.copy()\n",
    "    \n",
    "    n_especes_entrée=len(df[cle_ID].unique())\n",
    "    n_obs_entrée=len(df)\n",
    "    print(\"En entrée : nombre d'espèces observées :\",n_especes_entrée)\n",
    "    print(\"En entrée : nombre d'obs :\",n_obs_entrée)\n",
    "    \n",
    "    colonnes_obligatoires=[cle_ID]\n",
    "    # Supprimer les lignes ou une donnée cruciale manque\n",
    "    df_cleaned = df.dropna(subset=colonnes_obligatoires)\n",
    "    \n",
    "    # Filtrer les lignes où 'taxonRank' est SPECIES, SUBSPECIES ou VARIETY\n",
    "    #valid_ranks = ['SPECIES', 'SUBSPECIES', 'VARIETY']\n",
    "    #df_cleaned = df_cleaned[df_cleaned['taxonRank'].isin(valid_ranks)].reset_index(drop=True)\n",
    "    \n",
    "    # Filtrer les lignes où 'taxonRank' est SPECIES, SUBSPECIES ou VARIETY\n",
    "    df_cleaned = df_cleaned[df_cleaned['occurrenceStatus']=='PRESENT'].reset_index(drop=True)\n",
    "    \n",
    "    df_cleaned[cle_ID] = df_cleaned[cle_ID].astype(int)\n",
    "    \n",
    "    df_cleaned.rename(columns={'grid_name': cle_geo}, inplace=True)\n",
    "    \n",
    "    # Ajouter des colonnes year, month, day et day_of_year\n",
    "    #df_cleaned[cle_date] = pd.to_datetime(df_cleaned[cle_date], utc=True, errors='coerce')\n",
    "    \n",
    "    # Now safely access .dt.year, .dt.month, etc., from df_cleaned\n",
    "    #df_cleaned['year'] = df_cleaned[cle_date].dt.year\n",
    "    \n",
    "    # Convertir 'individualCount' en numérique, en forçant les erreurs à NaN\n",
    "    df_cleaned['individualCount'] = pd.to_numeric(df_cleaned['individualCount'], errors='coerce')\n",
    "    \n",
    "    # Remplacer les NaN par 1\n",
    "    df_cleaned['individualCount'].fillna(1, inplace=True)\n",
    "    \n",
    "    \n",
    "    print(f\"En sortie : nombre d'espèces observées :{len(df_cleaned[cle_ID].unique())} soit une perte de {100-(round(len(df_cleaned[cle_ID].unique())/n_especes_entrée*100))}%\")\n",
    "    print(f\"En sortie : nombre d'obs :{len(df_cleaned)} soit une perte de {100-round(len(df_cleaned)/n_obs_entrée*100)} %\") \n",
    "    # Grouper les données par maille et par période \n",
    "\n",
    "    annee_mini=1\n",
    "    bornes_temporelles=[1800, 1990,2010, 2024] \n",
    "    \n",
    "    df_maille_espece=formater_maille_espece_GBIF(df_cleaned,cle_geo,cle_ID,annee_mini,bornes_temporelles)\n",
    "    \n",
    "    print(f\"En sortie : nombre d'obs :{len(df_cleaned[df_cleaned['year']>annee_mini])} soit une perte de {100-round(len(df_cleaned[df_cleaned['year']>annee_mini])/n_obs_entrée*100)} %\") \n",
    "\n",
    "    dico_noms_vernaculaires_merged = pd.read_csv(r\"C:\\Users\\anormand\\Documents\\Projet Python\\Biodiv\\Data\\TAXO_GBIF\\dico_noms_vernaculaires_merged.csv\")\n",
    "\n",
    "    df_maille_espece=pd.merge(df_maille_espece,dico_noms_vernaculaires_merged,on=cle_ID,how=\"left\")\n",
    "    \n",
    "    # Sauvegarder les données groupées\n",
    "    \n",
    "    colonnes_a_conserver = ['kingdom','phylum','class','order','family','genus','species',\n",
    "                         'nombreObs',cle_ID,cle_geo,'periode','taxonRank','vernacularName_fr','vernacularName_en','occurrenceID']\n",
    "    df_to_save=df_maille_espece[colonnes_a_conserver]\n",
    "    df_to_save.to_csv(\"C:/Users/anormand/Documents/Projet Python/Biodiv/Data/GBIF_\"+country_name.replace(' ', '_')\n",
    "                      +\"/data_GBIF_\"+zone_name_str+'_'+cle_geo+\"_periodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27bcf3c2-fdb5-4b0f-ae9c-f3bc218db742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:6: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5,9,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,19,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,19,21,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5,6,19,21,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:38: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(fichier, chunksize=chunksize, sep='\\t',on_bad_lines='skip',usecols=colonnes_a_importer):\n"
     ]
    }
   ],
   "source": [
    "zone_name=[\"66\",\"11\",\"81\",\"34\",\"12\",\"48\",\"30\",\"07\",\"26\",\"84\",\"13\",\"05\",\"04\",\"83\",\"06\"]\n",
    "var_name=\"code\"\n",
    "zone_gpd=departement_gpd\n",
    "country_name=\"France\"\n",
    "grid_size_km=1\n",
    "\n",
    "df_biodiv=importer_data_zone(zone_name,var_name,zone_gpd,country_name,grid_size_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a26202-5f07-4e47-8a64-87f4afec5745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En entrée : nombre d'espèces observées : 58019\n",
      "En entrée : nombre d'obs : 53611778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['individualCount'].fillna(1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sortie : nombre d'espèces observées :57939 soit une perte de 0%\n",
      "En sortie : nombre d'obs :53479029 soit une perte de 0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periode\n",
      "Période 3: 2011 à 2024    28039835\n",
      "Période 2: 1991 à 2010    19648760\n",
      "Période 1: 1801 à 1990     4580716\n",
      "Name: count, dtype: int64\n",
      "En sortie : nombre d'obs :52395557 soit une perte de 2 %\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En entrée : nombre d'espèces observées : 58019\n",
      "En entrée : nombre d'obs : 53611778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['individualCount'].fillna(1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sortie : nombre d'espèces observées :57939 soit une perte de 0%\n",
      "En sortie : nombre d'obs :53479029 soit une perte de 0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periode\n",
      "Période 3: 2011 à 2024    28039835\n",
      "Période 2: 1991 à 2010    19648760\n",
      "Période 1: 1801 à 1990     4580716\n",
      "Name: count, dtype: int64\n",
      "En sortie : nombre d'obs :52395557 soit une perte de 2 %\n",
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En entrée : nombre d'espèces observées : 58019\n",
      "En entrée : nombre d'obs : 53611778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['individualCount'].fillna(1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sortie : nombre d'espèces observées :57939 soit une perte de 0%\n",
      "En sortie : nombre d'obs :53479029 soit une perte de 0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periode\n",
      "Période 3: 2011 à 2024    28039835\n",
      "Période 2: 1991 à 2010    19648760\n",
      "Période 1: 1801 à 1990     4580716\n",
      "Name: count, dtype: int64\n",
      "En sortie : nombre d'obs :52395557 soit une perte de 2 %\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En entrée : nombre d'espèces observées : 58019\n",
      "En entrée : nombre d'obs : 53611778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['individualCount'].fillna(1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sortie : nombre d'espèces observées :57939 soit une perte de 0%\n",
      "En sortie : nombre d'obs :53479029 soit une perte de 0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periode\n",
      "Période 3: 2011 à 2024    28039835\n",
      "Période 2: 1991 à 2010    19648760\n",
      "Période 1: 1801 à 1990     4580716\n",
      "Name: count, dtype: int64\n",
      "En sortie : nombre d'obs :52395557 soit une perte de 2 %\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En entrée : nombre d'espèces observées : 58019\n",
      "En entrée : nombre d'obs : 53611778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['individualCount'].fillna(1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sortie : nombre d'espèces observées :57939 soit une perte de 0%\n",
      "En sortie : nombre d'obs :53479029 soit une perte de 0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periode\n",
      "Période 3: 2011 à 2024    28039835\n",
      "Période 2: 1991 à 2010    19648760\n",
      "Période 1: 1801 à 1990     4580716\n",
      "Name: count, dtype: int64\n",
      "En sortie : nombre d'obs :52395557 soit une perte de 2 %\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En entrée : nombre d'espèces observées : 58019\n",
      "En entrée : nombre d'obs : 53611778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['individualCount'].fillna(1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sortie : nombre d'espèces observées :57939 soit une perte de 0%\n",
      "En sortie : nombre d'obs :53479029 soit une perte de 0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periode\n",
      "Période 3: 2011 à 2024    28039835\n",
      "Période 2: 1991 à 2010    19648760\n",
      "Période 1: 1801 à 1990     4580716\n",
      "Name: count, dtype: int64\n",
      "En sortie : nombre d'obs :52395557 soit une perte de 2 %\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En entrée : nombre d'espèces observées : 58019\n",
      "En entrée : nombre d'obs : 53611778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['individualCount'].fillna(1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sortie : nombre d'espèces observées :57939 soit une perte de 0%\n",
      "En sortie : nombre d'obs :53479029 soit une perte de 0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periode\n",
      "Période 3: 2011 à 2024    28039835\n",
      "Période 2: 1991 à 2010    19648760\n",
      "Période 1: 1801 à 1990     4580716\n",
      "Name: count, dtype: int64\n",
      "En sortie : nombre d'obs :52395557 soit une perte de 2 %\n",
      "07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En entrée : nombre d'espèces observées : 58019\n",
      "En entrée : nombre d'obs : 53611778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:135: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['individualCount'].fillna(1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En sortie : nombre d'espèces observées :57939 soit une perte de 0%\n",
      "En sortie : nombre d'obs :53479029 soit une perte de 0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'periode'] = pd.cut(df['year'], bins=bornes_temporelles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periode\n",
      "Période 3: 2011 à 2024    28039835\n",
      "Période 2: 1991 à 2010    19648760\n",
      "Période 1: 1801 à 1990     4580716\n",
      "Name: count, dtype: int64\n",
      "En sortie : nombre d'obs :52395557 soit une perte de 2 %\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3548218560.py:62: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  zone_geometry = zone.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:44: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  country_geometry = country.geometry.unary_union  # Combine all geometries into one\n",
      "C:\\Users\\anormand\\AppData\\Local\\Temp\\ipykernel_9756\\3174758167.py:94: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  grid = grid[grid.intersects(country.unary_union)]\n"
     ]
    }
   ],
   "source": [
    "for(zonename)in zone_name:\n",
    "    print(zonename)\n",
    "    grid_size_km=[2]\n",
    "    for grid_size in grid_size_km:\n",
    "        formater_data_PN_all_in_one(df_biodiv,[zonename],var_name,zone_gpd,country_name,grid_size,\n",
    "                                        cle_ID='speciesKey',cle_date='year',\n",
    "                                        annee_mini=0,bornes_temporelles=[1800, 1990,2010, 2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c5f0599-773c-4f1e-b560-adfa82f30362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(zonename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cf8571-1f0e-4807-8b17-ab9814d16c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['66']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[zonename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcebf5c9-2ac1-4946-9374-2cbc4fd84c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
